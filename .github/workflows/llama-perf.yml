name: Llama Performance Test

on:
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run-perf-model:
    runs-on: linux-mi355-8
    steps:
      - name: Checkout plugin repo
        uses: actions/checkout@v4
        with:
          ref: rocm-jaxlib-v0.6.0
      - name: Download wheels
        run: |
         mkdir -p wheelhouse && cd wheelhouse/
         curl -O -L https://github.com/ROCm/rocm-jax/releases/download/rocm-jax-v0.6.0/jax_rocm7_pjrt-0.6.0-py3-none-manylinux_2_28_x86_64.whl
         curl -O -L https://github.com/ROCm/rocm-jax/releases/download/rocm-jax-v0.6.0/jax_rocm7_plugin-0.6.0-cp312-cp312-manylinux_2_28_x86_64.whl
      - name: Build docker
        run: |
          python3 build/ci_build \
          --rocm-version=7.0.2 \
          --rocm-build-num=43 \
          --rocm-build-job=compute-rocm-rel-7.0 \
          build_dockers \
          --filter ubu24
      - name: Checkout source repo
        uses: actions/checkout@v4
        with:
          repository: AMD-AGI/scif_repro
          token: ${{ secrets.SECRET_TOKEN }}
          path: llama-perf
      - name: Run container
        run: |
          docker run --name perf-run -it -d --network=host \
          --device=/dev/kfd --device=/dev/dri --ipc=host --shm-size 32G \
          --group-add video --cap-add=SYS_PTRACE --security-opt seccomp=unconfined \
          -v "${{ github.workspace }}:/workspace" jax-ubu24.rocm702
      - name: Print workspace
        run: |
          docker exec perf-run bash -lc '
            ls -la /workspace'
      - name: Install deps
        run: |
          docker exec perf-run bash -lc '
            apt-get update
            apt-get install -y git'
      - name: Build TE-wheel
        run: |
          docker exec perf-run bash -lc '
            git clone https://github.com/rocm/transformerengine
            cd transformerengine
            git checkout a6cf0d8c37f267b5de81d8ae996de4da8daf9269
            export PIP_BREAK_SYSTEM_PACKAGES=1
            export NVTE_FRAMEWORK=jax
            export NVTE_ROCM_ARCH=gfx950
            export NVTE_USE_ROCM=1
            export HIP_PLATFORM=amd
            export CU_NUM=240
            export NVTE_FUSED_ATTN_AOTRITON=0
            pip install setuptools ninja
            pip install cmake==4.1.0
            git submodule update --init --recursive
            python3 setup.py bdist_wheel'
      - name: Install TE-wheel
        run: |
          docker exec perf-run bash -lc '
            pip install /transformerengine/dist/*.whl --break-system-packages'
      - name: Run model
        run: |
          docker exec perf-run bash -lc '
            cd /workspace/llama-perf
            python3 kylix/max/projects/llama/main.py -- --config=kylix.max.projects.llama.config.train_moe.executor_config --config_overrides='[dataloaders[0].operations[5].batch_size=128;dataloaders[0].num_operation_workers=16;model.mha_use_transformer_engine=True;optimizer.total_steps=200]''
